{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: RAG Query Pipeline with Llama\n",
    "\n",
    "This notebook brings everything together:\n",
    "1. **Retrieve** - Search ChromaDB for relevant services\n",
    "2. **Augment** - Add those services as context\n",
    "3. **Generate** - Use Llama to create helpful responses\n",
    "\n",
    "**Make sure Ollama is running:** Open a terminal and run `ollama serve`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Only need to run once, will install quietly \n",
    "!pip install ollama -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Our Existing Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded!\n",
      "Connected to ChromaDB with 1719 services\n",
      "Loaded 1719 full service records\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load embedding model (same one from notebook 02)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Embedding model loaded!\")\n",
    "\n",
    "# Connect to ChromaDB (created in notebook 02)\n",
    "chroma_client = chromadb.PersistentClient(path=\"../data/chroma_db\")\n",
    "collection = chroma_client.get_collection(\"services\")\n",
    "print(f\"Connected to ChromaDB with {collection.count()} services\")\n",
    "\n",
    "# Load full service data (for detailed responses)\n",
    "with open('../data/homeless_services_hackathon.json', 'r') as f:\n",
    "    all_services = json.load(f)\n",
    "print(f\"Loaded {len(all_services)} full service records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Ollama Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama connection successful!\n",
      "Response: Hello, I am ready!\n"
     ]
    }
   ],
   "source": [
    "# Test that Ollama is running\n",
    "try:\n",
    "    response = ollama.chat(model='llama3.2', messages=[\n",
    "        {'role': 'user', 'content': 'Say \"Hello, I am ready!\" and nothing else.'}\n",
    "    ])\n",
    "    print(\"Ollama connection successful!\")\n",
    "    print(f\"Response: {response['message']['content']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure Ollama is running: open a terminal and run 'ollama serve'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "def search_services(query, n_results=5):\n",
    "    \"\"\"\n",
    "    Search for services matching the query using semantic similarity.\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def format_services_for_llm(search_results):\n",
    "    \"\"\"\n",
    "    Format search results into a clear context string for the LLM.\n",
    "    \"\"\"\n",
    "    services_text = \"\"\n",
    "    \n",
    "    for i, (meta, doc) in enumerate(zip(search_results['metadatas'][0], search_results['documents'][0])):\n",
    "        services_text += f\"\"\"\n",
    "---\n",
    "SERVICE {i+1}: {meta.get('service_name', 'Unknown')}\n",
    "Organization: {meta.get('organization', 'N/A')}\n",
    "Phone: {meta.get('phone', 'N/A')}\n",
    "Address: {meta.get('address', 'N/A')}\n",
    "Types: {meta.get('types', 'N/A')}\n",
    "Area Served: {meta.get('area_served', 'N/A')}\n",
    "\n",
    "Full Details:\n",
    "{doc[:1500]}\n",
    "\"\"\"\n",
    "    \n",
    "    return services_text\n",
    "\n",
    "\n",
    "def ask_case_manager_assistant(user_query, n_services=5):\n",
    "    \"\"\"\n",
    "    Main RAG function: Search for services and generate a helpful response.\n",
    "    \"\"\"\n",
    "    # Step 1: RETRIEVE - Search for relevant services\n",
    "    search_results = search_services(user_query, n_results=n_services)\n",
    "    \n",
    "    # Step 2: AUGMENT - Format services as context\n",
    "    services_context = format_services_for_llm(search_results)\n",
    "    \n",
    "    # Step 3: GENERATE - Create the prompt and get LLM response\n",
    "    system_prompt = \"\"\"You are a helpful assistant for case managers working with homeless and at-risk populations in San Diego.\n",
    "\n",
    "Your job is to:\n",
    "1. Analyze the services provided in the context\n",
    "2. Recommend the most relevant services for the client's situation\n",
    "3. Explain eligibility requirements clearly\n",
    "4. Provide contact information and next steps\n",
    "5. Note any important details (hours, documents needed, etc.)\n",
    "\n",
    "Be concise but thorough. If a service doesn't seem like a good match, say so.\n",
    "Always prioritize the client's immediate needs.\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"A case manager is asking: \"{user_query}\"\n",
    "\n",
    "Here are the relevant services from our database:\n",
    "{services_context}\n",
    "\n",
    "Based on these services, provide helpful recommendations for the case manager.\"\"\"\n",
    "\n",
    "    # Call Llama via Ollama\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': user_message}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'answer': response['message']['content'],\n",
    "        'services_found': [m['service_name'] for m in search_results['metadatas'][0]]\n",
    "    }\n",
    "\n",
    "print(\"RAG pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: I have a homeless veteran who needs emergency shelter tonight\n",
      "======================================================================\n",
      "\n",
      "SERVICES FOUND:\n",
      "  - National Call Center for Homeless Veterans\n",
      "  - Harm Reduction Shelter\n",
      "  - Emergency Adult Shelter VVSD\n",
      "  - Emergency Adult Shelter VVSD\n",
      "  - Homeless Veterans' Reintegration Program\n",
      "\n",
      "======================================================================\n",
      "ASSISTANT RESPONSE:\n",
      "======================================================================\n",
      "**Recommendations for the Homeless Veteran**\n",
      "\n",
      "Given the urgency of providing emergency shelter for the homeless veteran, I recommend:\n",
      "\n",
      "1. **Service 2: Harm Reduction Shelter**: This service is specifically designed to provide a safe haven and support services for individuals experiencing homelessness with substance use conditions, including veterans. It's likely that this individual would benefit from the harm reduction approach and access to partner service providers.\n",
      "2. **Service 3: Emergency Adult Shelter VVSD (Male)**: As the veteran is male, this shelter may be a more suitable option. However, please note that this shelter has an income limitation, which might not be relevant for emergency situations.\n",
      "\n",
      "**Next Steps**\n",
      "\n",
      "1. Contact Service 2: Harm Reduction Shelter at (619) 860-2800 to inquire about available space and intake procedures.\n",
      "2. If space is limited or not available, contact Service 3: Emergency Adult Shelter VVSD (Male) at (619) 233-8500 for assistance.\n",
      "\n",
      "**Additional Considerations**\n",
      "\n",
      "* The veteran may benefit from additional services beyond emergency shelter, such as mental health support, vocational assessments, and job placement assistance. Service 5: Homeless Veterans' Reintegration Program could be a valuable resource in this case.\n",
      "* Please ensure that the veteran's discharge status is verified before referring them to any service.\n",
      "\n",
      "**Important Details**\n",
      "\n",
      "* Service 2: Harm Reduction Shelter requires a meeting with a case manager prior to admission, but same-day intake may be possible.\n",
      "* Service 3: Emergency Adult Shelter VVSD (Male) has limited space and requires referral through the Coordinated Entry System (CES).\n"
     ]
    }
   ],
   "source": [
    "# Test query 1: Veteran shelter\n",
    "query = \"I have a homeless veteran who needs emergency shelter tonight\"\n",
    "\n",
    "print(f\"QUERY: {query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = ask_case_manager_assistant(query)\n",
    "\n",
    "print(\"\\nSERVICES FOUND:\")\n",
    "for svc in result['services_found']:\n",
    "    print(f\"  - {svc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSISTANT RESPONSE:\")\n",
    "print(\"=\" * 70)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Single mother with 2 kids facing eviction, needs rent assistance and possibly shelter\n",
      "======================================================================\n",
      "\n",
      "SERVICES FOUND:\n",
      "  - Long Term Transitional Housing\n",
      "  - Rent and Utility Payment Assistance\n",
      "  - City of San Diego Eviction Prevention Program\n",
      "  - Emergency Family Shelter\n",
      "  - Transitional Housing for Families, St Vincent de Paul Village\n",
      "\n",
      "======================================================================\n",
      "ASSISTANT RESPONSE:\n",
      "======================================================================\n",
      "After reviewing the provided services, I recommend the following:\n",
      "\n",
      "1. **City of San Diego Eviction Prevention Program**: Given the family's immediate need to prevent eviction, this program would be an excellent starting point. The case manager can help the family navigate the application process and ensure they meet the eligibility criteria. This service will provide the necessary assistance to prevent homelessness.\n",
      "2. **Long Term Transitional Housing at Solutions for Change**: Although it offers a longer-term solution, I recommend considering transitional housing as an option. It provides essential support services, such as case management, employment and education assistance, mental health and substance abuse support, and childcare programs for children living in the housing with their families.\n",
      "3. **Emergency Family Shelter at Interfaith Community Services**: If the family needs immediate shelter, this service could be a good alternative or complement to transitional housing. However, it's essential to consider whether this service aligns with the family's long-term goals and needs.\n",
      "\n",
      "Eligibility requirements:\n",
      "\n",
      "* City of San Diego Eviction Prevention Program: Household income at or below 80% of San Diego's Area Median Income ($121,250/year for a family of four)\n",
      "* Long Term Transitional Housing at Solutions for Change: Parent(s) with minor dependent children or pregnant, homeless according to HUD guidelines, willing to work full-time, and pass a drug test\n",
      "* Emergency Family Shelter at Interfaith Community Services: Families must be homeless or at risk of homelessness, reside within the North County of San Diego, pass a background check, meet HUD requirements, and include one adult and at least one child under the age of 18.\n",
      "\n",
      "Important details:\n",
      "\n",
      "* City of San Diego Eviction Prevention Program: Can be contacted through their hotline (877) 534-2524\n",
      "* Solutions for Change: Long-term transitional housing requires a minimum stay of two years; case management services are available throughout the duration\n",
      "* Interfaith Community Services: Families must pass a background check and meet HUD requirements; services may have limited availability\n",
      "\n",
      "Next steps:\n",
      "\n",
      "1. Contact the City of San Diego Eviction Prevention Program to discuss eligibility and application procedures.\n",
      "2. Explore Long Term Transitional Housing options at Solutions for Change, considering the family's long-term goals and needs.\n",
      "3. If necessary, refer the family to Emergency Family Shelter at Interfaith Community Services for temporary shelter.\n",
      "\n",
      "Please note that the recommended services should be tailored to the specific needs and circumstances of the single mother with two children facing eviction. The case manager should provide clear guidance and support throughout the application process.\n"
     ]
    }
   ],
   "source": [
    "# Test query 2: Family with children\n",
    "query = \"Single mother with 2 kids facing eviction, needs rent assistance and possibly shelter\"\n",
    "\n",
    "print(f\"QUERY: {query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = ask_case_manager_assistant(query)\n",
    "\n",
    "print(\"\\nSERVICES FOUND:\")\n",
    "for svc in result['services_found']:\n",
    "    print(f\"  - {svc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSISTANT RESPONSE:\")\n",
    "print(\"=\" * 70)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Young adult age 20 experiencing mental health crisis, needs counseling and possibly housing\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test query 3: Mental health\n",
    "query = \"Young adult age 20 experiencing mental health crisis, needs counseling and possibly housing\"\n",
    "\n",
    "print(f\"QUERY: {query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = ask_case_manager_assistant(query)\n",
    "\n",
    "print(\"\\nSERVICES FOUND:\")\n",
    "for svc in result['services_found']:\n",
    "    print(f\"  - {svc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSISTANT RESPONSE:\")\n",
    "print(\"=\" * 70)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Query Mode\n",
    "\n",
    "Run this cell to ask your own questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive mode - change this query and run the cell\n",
    "your_query = \"elderly person needs help with food and utilities\"\n",
    "\n",
    "print(f\"QUERY: {your_query}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = ask_case_manager_assistant(your_query)\n",
    "\n",
    "print(\"\\nSERVICES FOUND:\")\n",
    "for svc in result['services_found']:\n",
    "    print(f\"  - {svc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ASSISTANT RESPONSE:\")\n",
    "print(\"=\" * 70)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Compare Services Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_services(query, client_profile):\n",
    "    \"\"\"\n",
    "    Ask the LLM to compare services and recommend the best fit.\n",
    "    \"\"\"\n",
    "    search_results = search_services(query, n_results=5)\n",
    "    services_context = format_services_for_llm(search_results)\n",
    "    \n",
    "    prompt = f\"\"\"Compare these services for this client:\n",
    "\n",
    "CLIENT PROFILE:\n",
    "{client_profile}\n",
    "\n",
    "AVAILABLE SERVICES:\n",
    "{services_context}\n",
    "\n",
    "Please:\n",
    "1. Create a comparison table of the top 3 most relevant services\n",
    "2. Recommend which service is the BEST fit and why\n",
    "3. List any services that are NOT a good fit and why\n",
    "4. Suggest a step-by-step action plan for the case manager\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# Example comparison\n",
    "client = \"\"\"\n",
    "- 45 year old male\n",
    "- Veteran (Army, 8 years)\n",
    "- Currently sleeping in car\n",
    "- Has part-time job at warehouse\n",
    "- No mental health or substance issues\n",
    "- Needs: stable housing, maybe help with deposit\n",
    "\"\"\"\n",
    "\n",
    "print(\"CLIENT PROFILE:\")\n",
    "print(client)\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCOMPARISON & RECOMMENDATIONS:\")\n",
    "print(\"=\" * 70)\n",
    "print(compare_services(\"veteran housing assistance\", client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We now have a working RAG pipeline that:\n",
    "\n",
    "1. **Searches** our services database semantically\n",
    "2. **Generates** helpful, contextual responses using Llama\n",
    "3. **Compares** services for specific client profiles\n",
    "\n",
    "### Next Steps (Future Enhancements)\n",
    "\n",
    "| Component | Purpose | Model |\n",
    "|-----------|---------|-------|\n",
    "| Information Extraction | Structure messy fields (eligibility, hours) | DistilBERT / spaCy |\n",
    "| Classification | Auto-tag services, predict eligibility | DistilBERT / BERT |\n",
    "| Recommendation Ranking | Score services for specific clients | XGBoost + embeddings |\n",
    "| Web Interface | Let case managers use this easily | Streamlit / Gradio |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
